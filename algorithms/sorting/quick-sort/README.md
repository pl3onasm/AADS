# Quicksort

Quicksort is a comparison sort based on the divide and conquer paradigm. It divides the original problem into subproblems of the same type by selecting a pivot element around which the array is then partitioned. The result of this partitioning is that the pivot is in its final sorted position, and we are left with two subarrays: one with all elements less than the pivot and another with all elements greater than the pivot. These subarrays are then recursively sorted using the same process. The base case is when the subarray contains only one element, at which point the entire subarray is sorted. Unlike [merge sort](https://github.com/pl3onasm/CLRS/tree/main/algorithms/sorting/merge-sort), quicksort has no need for a combine step in the form of a merge procedure, since the partitioning step already ensures that the elements are in their final sorted positions. Quicksort is also an unstable in-place sort, meaning that it does not preserve the relative order of elements with equal keys, and it does not require any additional memory.

Clearly, the partitioning is the crucial step of the algorithm. This is done by maintaining a single pointer which points to the dividing line between the elements less than the pivot and those greater than the pivot. This pointer is initialized to the first element of the array. Then, for each element in the array, if the element is less than the pivot, the pointer is incremented and the element is swapped with the element at the pointer. This ensures that all elements less than the pivot are to the left of the pointer, and all elements greater than the pivot are to the right of the same pointer. Finally, the pivot is swapped with the element at the pointer, placing it in its final sorted position. The pointer is returned, and quick sort is then recursively called on the subarrays to the left and right of the pivot. Once the base case is reached, the array is sorted.

Much of quicksort's performance depends on the pivot selection, since this determines how balanced the partitioning is, i.e. how evenly the array is divided, and thus how many recursive calls are made. If the pivot is chosen to be the last element of the array, and the array is already sorted, then the partitioning will result in one subarray of size 1 and one subarray of size n-1, where n is the size of the original array. It is quite ironic that an already sorted array thus elicits quicksort's worst case time complexity of $O(n^2)$. The average case time complexity, however, is $O(n \log n)$, which is the same as merge sort's time complexity. This is because the partitioning takes $O(n)$ time, and results, in the ideal case, in two subarrays of size $n/2$ (this would be the case if the pivot were the median element of the array), which are then recursively sorted in $\log n$ recursive calls.

Implementation: [Quicksort](https://github.com/pl3onasm/CLRS/tree/main/algorithms/sorting/quick-sort/quicksort.c)

A generic implementation: [Generic Quicksort](https://github.com/pl3onasm/CLRS/tree/main/algorithms/sorting/quick-sort/genqsort.c)

In order to avoid the worst case time complexity, the pivot can be chosen randomly. This ensures that the partitioning is balanced on average, and thus the average case time complexity is maintained. The worst case time complexity is still $O(n^2)$, but the probability of this occurring is negligible. We say that the algorithm runs in expected $O(n \log n)$ time.

Implementation: [Randomized Quicksort](https://github.com/pl3onasm/CLRS/tree/main/algorithms/sorting/quick-sort/randomqsort.c)
